{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "28086fca-2cdd-41ac-b7bf-bc1af9f759a2",
      "metadata": {
        "id": "28086fca-2cdd-41ac-b7bf-bc1af9f759a2"
      },
      "source": [
        "# Laboratorio: Métodos de búsqueda"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e19abc1-82f0-4f28-9493-468e4227c14f",
      "metadata": {
        "id": "9e19abc1-82f0-4f28-9493-468e4227c14f"
      },
      "source": [
        "En las clases anteriores creaste códigos para realizar búsquedas aleatorias (Simulated Annealing) y búsquedas dirigidas (Optimización Bayesiana). Estos métodos de búsqueda se utilizan para facilitar el proceso de optimización de funciones objetivos compleja y costosas de computar."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "038474ce-6e2f-4d45-895a-bb17f7c8871d",
      "metadata": {
        "id": "038474ce-6e2f-4d45-895a-bb17f7c8871d"
      },
      "source": [
        "En este laboratorio usaremos el dataset de los diferentes tipos de iris, y sus longitudes y anchos de pétalos y sépalos. Utilizaremos un RandomForest para crear un modelo de clasificación y el métrico F1 para decidir cuál es el mejor modelo de acuerdo a lo que tenemos disponible."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c04956ea-14f4-419e-adf8-add3b81da443",
      "metadata": {
        "id": "c04956ea-14f4-419e-adf8-add3b81da443"
      },
      "source": [
        "1. Carga el dataset de Iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "aad912f2-1359-437e-af68-3c8cca8d1b03",
      "metadata": {
        "id": "aad912f2-1359-437e-af68-3c8cca8d1b03"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "X, y = datasets.load_iris(return_X_y=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b97ad91-d82b-491c-ac5d-be6f872c5334",
      "metadata": {
        "id": "9b97ad91-d82b-491c-ac5d-be6f872c5334"
      },
      "source": [
        "2. Importa el archivo `Bosque.py`.\n",
        "\n",
        "Este archivo contiene la función `RegresionBosque`, que recibe:\n",
        "- X: las características independientes\n",
        "- y: la variable de respuesta\n",
        "- árboles: cantidad total de árboles\n",
        "- profundidad de bosque: niveles de profundidad del bosque\n",
        "\n",
        "Su salida es:\n",
        "- modelo: El objeto con el modelo ajustado\n",
        "- f1: El métrico que califica qué tan bueno es el modelo que se ajustó.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "23f875f1-a72a-4a57-8355-16d6bb9fb33a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23f875f1-a72a-4a57-8355-16d6bb9fb33a",
        "outputId": "3ab24cf4-6af9-41c2-d383-d79610f8d24d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9444444444444444"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import Bosque\n",
        "modelo, f1 = Bosque.RegresionBosque(X, y, 10, 3)\n",
        "f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ac2825-33ac-4919-9ccb-8324701ce99f",
      "metadata": {
        "id": "15ac2825-33ac-4919-9ccb-8324701ce99f"
      },
      "source": [
        "### Actividad 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8eb265f-9ccf-4fb4-b8c0-8fe221ea534c",
      "metadata": {
        "id": "a8eb265f-9ccf-4fb4-b8c0-8fe221ea534c"
      },
      "source": [
        "Inicializa un espacio con 5 muestras en nuestro dominio de variables independientes:\n",
        "- árboles: números enteros entre 5 y 50.\n",
        "- profundidad: números enteros entre 2 y 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ed7c396-af97-49a6-828e-c5d63c1b6999",
      "metadata": {
        "id": "1ed7c396-af97-49a6-828e-c5d63c1b6999"
      },
      "source": [
        "Utiliza optimización Bayesiana para encontrar la combinación de árboles y profundidad que **maximice** el métrico F1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prueba 1 creada  por mi\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import Bosque\n",
        "\n",
        "def f1_objective(parametros):\n",
        "    n_estimators, max_depth = parametros\n",
        "    modelo, f1 = Bosque.RegresionBosque(X, y, int(n_estimators), int(max_depth))\n",
        "    return f1\n",
        "\n",
        "n_estimators_values = np.linspace(5, 50, 10)\n",
        "max_depth_values = np.linspace(2, 10, 9)\n",
        "\n",
        "X_train = np.random.uniform([5, 2], [50, 10], size=(5, 2))\n",
        "y_train = np.array([f1_objective(x) for x in X_train])\n",
        "\n",
        "kernel = 1.0 * RBF(length_scale=1)\n",
        "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
        "gp.fit(X_train, y_train)\n",
        "\n",
        "n = 30\n",
        "f1_scores = []\n",
        "\n",
        "for i in range(n):\n",
        "    X= np.array(np.meshgrid(n_estimators_values, max_depth_values)).T.reshape(-1, 2)\n",
        "    y_pred, y_std = gp.predict(X, return_std=True)\n",
        "    next_point = X[np.argmax(y_std)]\n",
        "    next_value = f1_objective(next_point)\n",
        "    X_train = np.vstack([X_train, next_point])\n",
        "    y_train = np.append(y_train, next_value)\n",
        "    gp.fit(X_train, y_train)\n",
        "    f1_scores.append(-y_train.min())\n",
        "\n",
        "plt.plot(f1_scores)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "7G0d73xI3DMr",
        "outputId": "4a50de0a-9bf6-4001-e1e8-3211cb959a2a"
      },
      "id": "7G0d73xI3DMr",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [90, 150]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-996354f8315a>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mnext_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mnext_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_point\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-996354f8315a>\u001b[0m in \u001b[0;36mf1_objective\u001b[0;34m(parametros)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf1_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparametros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparametros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodelo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBosque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegresionBosque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Bosque.py\u001b[0m in \u001b[0;36mRegresionBosque\u001b[0;34m(X, y, arboles, profundidad)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mRegresionBosque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marboles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofundidad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marboles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofundidad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"micro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2780\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2782\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [90, 150]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "de00bcfe-9350-4954-80f6-1ea060276da1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de00bcfe-9350-4954-80f6-1ea060276da1",
        "outputId": "043e9135-9313-4589-a7bd-fb29febc9c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración 5/30: Mejor F1 score = 0.9556\n",
            "Iteración 10/30: Mejor F1 score = 0.9556\n",
            "Iteración 15/30: Mejor F1 score = 0.9667\n",
            "Iteración 20/30: Mejor F1 score = 0.9667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración 25/30: Mejor F1 score = 0.9667\n",
            "Iteración 30/30: Mejor F1 score = 0.9667\n",
            "\n",
            "Mejores parámetros encontrados: \n",
            "Número de árboles: 16, Profundidad: 3\n",
            "Mejor F1 score: 0.9667\n"
          ]
        }
      ],
      "source": [
        "#Prueba 2 hecha con IA\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def f1_objective(parametros):\n",
        "    n_estimators, max_depth = parametros\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=10)\n",
        "    mRF = RandomForestClassifier(n_estimators=int(n_estimators), max_depth=int(max_depth), random_state=10)\n",
        "    mRF.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = mRF.predict(X_test)\n",
        "\n",
        "    f1 = metrics.f1_score(y_test, y_pred, average=\"micro\")\n",
        "\n",
        "    return -f1\n",
        "\n",
        "bounds = np.array([[5, 50],\n",
        "                   [2, 10]])\n",
        "\n",
        "X_train = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(5, 2))\n",
        "y_train = np.array([f1_objective(x) for x in X_train])\n",
        "kernel = 1.0 * RBF(length_scale=1)\n",
        "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
        "gp.fit(X_train, y_train)\n",
        "\n",
        "n = 30\n",
        "\n",
        "for i in range(n):\n",
        "    X_grid = np.linspace(bounds[0, 0], bounds[0, 1], 50).reshape(-1, 1)\n",
        "    X_grid = np.hstack([X_grid, np.linspace(bounds[1, 0], bounds[1, 1], 50).reshape(-1, 1)])\n",
        "\n",
        "    y_pred, y_std = gp.predict(X_grid, return_std=True)\n",
        "\n",
        "    next_point = X_grid[np.argmax(y_std)]\n",
        "\n",
        "    next_value = f1_objective(next_point)\n",
        "\n",
        "    X_train = np.vstack([X_train, next_point])\n",
        "    y_train = np.append(y_train, next_value)\n",
        "\n",
        "    gp.fit(X_train, y_train)\n",
        "    if (i + 1) % 5 == 0:\n",
        "        print(f\"Iteración {i+1}/{n}: Mejor F1 score = {-y_train.min():.4f}\")\n",
        "\n",
        "best_params_idx = np.argmin(y_train)\n",
        "best_params = X_train[best_params_idx]\n",
        "print(f\"\\nMejores parámetros encontrados: \\nNúmero de árboles: {int(best_params[0])}, Profundidad: {int(best_params[1])}\")\n",
        "print(f\"Mejor F1 score: {-y_train.min():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e083a3c-fa68-4942-b5d3-f1f7130b4fbb",
      "metadata": {
        "id": "5e083a3c-fa68-4942-b5d3-f1f7130b4fbb"
      },
      "source": [
        "### Actividad 2:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2817a47c-0081-4376-b222-c65735f4ab9d",
      "metadata": {
        "id": "2817a47c-0081-4376-b222-c65735f4ab9d"
      },
      "source": [
        "Inicializa 2 vectores con posibles valores para las variables independientes:\n",
        "- árboles: números enteros entre 5 y 50\n",
        "- profundidad: números enteros entre 2 y 10\n",
        "\n",
        "Utiliza el algoritmo de Simulated Annealing que siga el siguiente orden:\n",
        "- Elige un punto de partida para las variables.\n",
        "- Selecciona al azar una de las dos para modificarlas.\n",
        "- Selecciona un elemento al azar de la lista que contiene los posibles valores de esa variable.\n",
        "- Sigue el algoritmo ($p$ y $q$) para decidir si usas esa combinación nueva o si mantienes la anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6286fe8-ec56-4871-9c31-8d4d3ca4c0ae",
      "metadata": {
        "id": "e6286fe8-ec56-4871-9c31-8d4d3ca4c0ae"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "239fa243-bd6d-4ec4-860a-2eae65cea710",
      "metadata": {
        "id": "239fa243-bd6d-4ec4-860a-2eae65cea710"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00442559-60d2-440a-9ba0-5217ea775ac7",
      "metadata": {
        "id": "00442559-60d2-440a-9ba0-5217ea775ac7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}